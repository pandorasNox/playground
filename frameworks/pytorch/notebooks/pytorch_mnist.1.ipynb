{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# steps\n",
    "\n",
    "## 1. collect (unprocessed) data [???]\n",
    "\n",
    "## 2 process data [k8s, spark, ???]\n",
    "- build processing model\n",
    "- e.g crop, scale, cut ... etc...\n",
    "\n",
    "## 3. move processed date in understandable directory structure [k8s, s3]\n",
    "\n",
    "## 4. load data (based on expected dir structure) [python]\n",
    "\n",
    "## 5. build model [python]\n",
    "\n",
    "## 6. train model [k8s, python]\n",
    "\n",
    "## 6.1 evaluate model [included in training]\n",
    "-> repeat 1 or 2 or 5\n",
    "-> repeat 6, 7\n",
    "\n",
    "## 8 (on success) deploy model ??? (pipeline) [CI/CD, k8s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "1.0.0.dev20181207\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"0.4.0\" == torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kwargs = {}\n",
    "\n",
    "train = dataloader(\n",
    "    MNIST(\n",
    "        'data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    ),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                         )\n",
      "    Target Transforms (if any): None\n",
      "\n",
      "test_data: Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Split: test\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "train_data = MNIST('./data', train=True, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "]), )\n",
    "\n",
    "test_data = MNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "]), )\n",
    "\n",
    "print(\"train_data:\", train_data)\n",
    "print(\"\")\n",
    "print(\"test_data:\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data [[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader\n",
    "dataloader_args = dict(shuffle=True, batch_size=64, num_workers=1, pin_memory=True)\n",
    "train_loader = dataloader.DataLoader(train_data, **dataloader_args)\n",
    "test_loader = dataloader.DataLoader(test_data, **dataloader_args)\n",
    "\n",
    "print(\"train_data\", train_data.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]\n",
      " - Numpy Shape: (60000, 28, 28)\n",
      " - Tensor Shape: torch.Size([60000, 28, 28])\n",
      " - Transformed Shape: torch.Size([28, 60000, 28])\n",
      " - min: tensor(0.)\n",
      " - max: tensor(1.)\n",
      " - mean: tensor(0.1305)\n",
      " - std: tensor(0.3081)\n",
      " - var: tensor(0.0949)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_data = train_data.train_data\n",
    "transformed_train_data = train_data.transform(train_data.data.cpu().numpy())\n",
    "\n",
    "print('[Train]')\n",
    "print(' - Numpy Shape:', train_data.data.cpu().numpy().shape)\n",
    "print(' - Tensor Shape:', train_data.data.size())\n",
    "print(' - Transformed Shape:', transformed_train_data.size())\n",
    "print(' - min:', torch.min(transformed_train_data))\n",
    "print(' - max:', torch.max(transformed_train_data))\n",
    "print(' - mean:', torch.mean(transformed_train_data))\n",
    "print(' - std:', torch.std(transformed_train_data))\n",
    "print(' - var:', torch.var(transformed_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOptimizer(net):\n",
    "    return optim.SGD(net.parameters(), lr=0.001, momentum=0.8)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_epoch_train(model, current_epoch, train_data_loader, optimizer):\n",
    "    model.train()\n",
    "    batch_losses = []\n",
    "    #model.eval()\n",
    "\n",
    "    for batch_id, (data, target) in enumerate(train_data_loader):\n",
    "        #if torch.cuda.is_available():\n",
    "        #if cuda #<= if gpu support, do something like\n",
    "            #data = data.cuda()\n",
    "            #target = target.cuda()\n",
    "            \n",
    "        #transform to variables\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        \n",
    "        #optimizer = createOptimizer(model) #<= not needed bec is passed\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(data) #out OR prediction\n",
    "        #criterion = nn.CrossEntropyLoss\n",
    "        criterion = F.nll_loss # criterion-fn\n",
    "        loss = criterion(out, target)\n",
    "        \n",
    "        batch_losses.append(loss.data[0])\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                current_epoch, \n",
    "                batch_id * len(data), \n",
    "                len(train_data_loader.dataset),\n",
    "                100. * batch_id / len(train_data_loader), \n",
    "                loss.data[0]\n",
    "            ),\n",
    "            end=''\n",
    "        )\n",
    "        \n",
    "    return (model, batch_losses)\n",
    "\n",
    "def train(net, train_data_loader, optimizer, count_epochs=15):\n",
    "    #check count_epochs >= 1\n",
    "    losses = []\n",
    "\n",
    "    for current_epoch in range(1, count_epochs):\n",
    "        (returnedNet, batch_losses) = single_epoch_train(net, current_epoch, train_data_loader, optimizer)\n",
    "        net = returnedNet\n",
    "        losses += batch_losses\n",
    "\n",
    "    return (net, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        \n",
    "        #add layers\n",
    "        #input_features = 10\n",
    "        conv1_inChannels = 1\n",
    "        conv1_outChannels = 10\n",
    "        conv1_kernalSize = 5\n",
    "        self.conv1 = nn.Conv2d(conv1_inChannels, conv1_outChannels, conv1_kernalSize)\n",
    "        \n",
    "        conv2_inChannels = conv1_outChannels\n",
    "        conv2_outChannels = 20\n",
    "        conv2_kernalSize = 5\n",
    "        self.conv2 = nn.Conv2d(conv2_inChannels, conv2_outChannels, conv2_kernalSize)\n",
    "        \n",
    "        self.conv_dropout = nn.Dropout2d\n",
    "        \n",
    "        self.fc1 = nn.Linear(320, 60) #fc1 = fully connected layer #320 = amount of pixels per image\n",
    "        self.fc2 = nn.Linear(60, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #conv1\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        #conv2        \n",
    "        x = self.conv2(x)\n",
    "        #x = self.conv_dropout(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #step to determine fc1 inputs??? = result leads to 320, but why, how to calc that???\n",
    "        #print(x.size())\n",
    "        #exit()\n",
    "        \n",
    "        #why???\n",
    "        x = x.view(-1, 320)\n",
    "        \n",
    "        #fc1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #fc2 ~ output\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=-2)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # helper function ??? why ???\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # attention: mini batch / stochachistig grad\n",
    "        num = 1\n",
    "        for i in size:\n",
    "            num *= i\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1326c08f21d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMNISTOptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyMNISTNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyMNISTNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMNISTOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-5bdb2177c15d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_data_loader, optimizer, count_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mreturnedNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturnedNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5bdb2177c15d>\u001b[0m in \u001b[0;36msingle_epoch_train\u001b[0;34m(model, current_epoch, train_data_loader, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "MyMNISTNet = MNISTNet()\n",
    "#MyMNISTNet.cuda() #<= if cuda\n",
    "\n",
    "MNISTOptimizer = createOptimizer(MyMNISTNet)\n",
    "\n",
    "train(MyMNISTNet, train_loader, MNISTOptimizer, count_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input has less dimensions than expected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-773f8e08b173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#print(Variable(evaluate_x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyMNISTNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0008d5c8dd39>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#conv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input has less dimensions than expected"
     ]
    }
   ],
   "source": [
    "#evaluate_x = Variable(test_loader.dataset.test_data.type_as(torch.FloatTensor()))\n",
    "#evaluate_y = Variable(test_loader.dataset.test_labels)\n",
    "\n",
    "evaluate_x = test_loader.dataset.test_data[0]\n",
    "#evaluate_x = Variable(evaluate_x)\n",
    "\n",
    "#evaluate_y = Variable(test_loader.dataset.test_labels[0])\n",
    "\n",
    "#print(Variable(evaluate_x))\n",
    "output = MyMNISTNet(evaluate_x)\n",
    "\n",
    "print(output)\n",
    "\n",
    "#pred = output.data.max(1)[1]\n",
    "#d = pred.eq(evaluate_y.data).cpu()\n",
    "#accuracy = d.sum()/d.size()[0]\n",
    "\n",
    "#print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAxtJREFUeJztmz1LI1EUhp9ZVrQI8YMsSMBsQEEREUEbbQQVieIPEPwHFnbaKUgaQbFSUPQnmEIQsREELQIKYmMXktgIrh+FhSDK3SJrsp4UmZHczCx7HgiBy2XuyZP3JHMnE8cYg1Lim98FBA0VIlAhAhUiUCECFSJQIQIVIlAhgu9eJkciEROPxy2VYpdcLsf9/b1TaZ4nIfF4nIuLi69X5SMDAwOu5mnLCFSIQIUIVIhAhQhUiECFCFSIQIUIPJ2pumVvbw+AnZ0dAKLRKA0NDQDMzMwA0NraCkBHR4eNEr6MJkRgJSHz8/NAYUMl2draAiAcDgPQ3d3t+fhtbW0ALCwsAO73KW6wImR3dxeAq6sroPCir6+vAbi8vATg5OQEgHQ6TSwWA+Dm5qbsWHV1dQBEIhEAbm9vSafTQElMNYVoywisJGR0dPTTM0Aikfg05+npCSgk5uMdPj8/LztWfX09AJ2dnQB0dXXx+PgIQHt7e5Ur14SUYSUhbmhubgZgZGSkOPZ3oiSpVAooJKu3txeA6enpqtelCRH4lhC33N3dATA7OwuAMYalpSUAWlpaqr5e4IVsbm4CJTFNTU3FD1gbaMsIApuQs7MzAFZWVj6N7+/v09PTY21dTYggsAk5PDwE4PX1FYCxsTEABgcHra4bSCEvLy8cHR0BpTPV5eVloLS3sYW2jCCQCVldXS3uiicmJgAYGhqqydqaEEGgEnJwcABAMpmksbERgMXFxZrWoAkRBCIhDw8PAMzNzQHw9vbG5OQkYP9rVuK7kPf39+LFo2w2CxSuxCeTSV/q0ZYR+J6QTCZTdlfS+vq6lcuDbtCECHxLSD6fB2B8fLw4tra2BsDU1JQvNYGPQra3t4GSGIDh4WEAHKfizYLW0JYR1Dwhp6enAGxsbNR6aVdoQgQ1T8jHpcHn5+fi2MctEaFQqNbllKEJEfh+YtbX18fx8TFg53cWzxhjXD/6+/vNv8qf2iu+Rm0ZgWM8/JHZcZxfQL7ixGDy0xjzo9IkT0L+B7RlBCpEoEIEKkSgQgQqRKBCBCpEoEIEvwEKw6jrEKgkZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA11JREFUeJztmz1LI1EUhp/o2ogiSEKwMQEbBRFBIQiCliIqouAUIhZW/gURCxHx20rwB1j4hYrYCNYWEhAtFCSIW4lsgliJWswWbibkTPyYxbnjsueBEDj3hDnz5j137p1JQrZto+QoCrqA74YKIlBBBCqIQAURqCACFUSggghUEMEPL8nhcNiOx+M+leIvNzc3pNPp0Ed5ngSJx+Mkk8m/rypAmpubP5WnLSNQQQSeWuYrWFhYAODx8RGA8/Nztre383JGR0dpaWkBYGhoyGh96hCBMYdYlgXA1taWaywUyp/8V1dXOTo6AqCtrQ2A6upqnyt8RR0iMOIQy7IKOgOgtraWjo4OAK6vrwHY398nlUoBsLa2BsDY2JiBSn0WJLtm2d3ddWL19fXA60kDhMNhysrKAHh+fgYgkUhwdnYGQCaT8bNEF9oyAl8dcnt7C4Bt244zDg8PAaiqqnLlZy/Jl5eXTqyrq8vPEl2oQwS+OqS7uxuAVCpFeXk5AJWVlW/mb2xsALm5JAiMXGVisdi74/Pz8wBcXV05sUQikfduCm0ZgfG9jOTg4ICJiQkAnp6eAIhGo8zMzABQWlpqtB51iCBwhySTSccZWSzLcvYwplGHCAJzSG9vL5BbqAEMDw8DMDU1FUhNEIAg2dXr8fEx8DqRRiIRAMbHxwGcvU0QaMsIjDukr68PgHQ67cQGBwcBqKmpMV2OC3WIwJhDsvc/Tk9P8+Lt7e1MTk6aKuNDjAiSyWSYnp4G3Bu3xsbGQCdRibaMwIhDFhcXOTk5yYtl1yHfqV1AHeLCiEOWlpZcsZWVFSDYRVgh1CGCwPYy2ccLJSUlBccrKiryxl9eXgB4eHhwcu7v7wFYXl52fb64uBiA2dlZT/dUAhOkoaHh3fGBgQEgd3f+7u4OgPX1dU/HiUajzh7pM2jLCIw4pLOzk729PU+f2dzcfHMs20ZFRbnvs6enB3D/Uqi1tdXTcdUhAiMO2dnZYW5uDij8zOXi4gIoPD+MjIwA+Y8y+vv7Aairq/vyWrFt+9OvpqYm+1/lT+0fnqO2jEAFEaggAhVEoIIIVBCBCiJQQQQh28MfmUOh0C/gp3/l+ErMtu3IR0meBPkf0JYRqCACFUSggghUEIEKIlBBBCqIQAUR/AZTesie1UWqVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(test_loader.dataset.test_data)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images_separately(images):\n",
    "    \"Plot the six MNIST images separately.\"\n",
    "    fig = plt.figure()\n",
    "    for j in range(1, 7):\n",
    "        ax = fig.add_subplot(1, 6, j)\n",
    "        ax.matshow(images[j-1], cmap = matplotlib.cm.binary)\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "    plt.show()\n",
    "\n",
    "def plot_image(image):\n",
    "    \"Plot a MNIST image.\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(4, 1, 1)\n",
    "    ax.matshow(image, cmap = matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.show()\n",
    "    \n",
    "plot_images_separately(test_loader.dataset.test_data)\n",
    "plot_images_separately([\n",
    "    test_loader.dataset.test_data[0],\n",
    "    test_loader.dataset.test_data[1],\n",
    "    test_loader.dataset.test_data[1],\n",
    "    test_loader.dataset.test_data[1],\n",
    "    test_loader.dataset.test_data[1],\n",
    "    test_loader.dataset.test_data[1],\n",
    "    test_loader.dataset.test_data[1],\n",
    "    test_loader.dataset.test_data[1]\n",
    "])\n",
    "plot_image(test_loader.dataset.test_data[0])\n",
    "plot_image(test_loader.dataset.test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
